{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Churn prediction project\n",
    "\n",
    "Logistic regression: g(xi)=SIGMOID(w0+wTxi) → outputs a number 0..1∈R\n",
    "sigmoid(z)= 1 / (1+exp(−z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/refs/heads/master/chapter-03-churn-prediction/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
    "#!curl -o churn.csv $url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"../../data/raw/churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all columns with their data (transpose col to row)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "cols = df.dtypes[df.dtypes == \"object\"].index\n",
    "df.head()\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the object feild to num and fix the col err value\n",
    "print(df.totalcharges[df.totalcharges == \"_\"])\n",
    "\n",
    "df.totalcharges = pandas.to_numeric(df.totalcharges, errors=\"coerce\")\n",
    "\n",
    "print(df.totalcharges.iloc[488])\n",
    "df.totalcharges = df.totalcharges.fillna(0)\n",
    "\n",
    "df.totalcharges[df.totalcharges == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.churn.head())\n",
    "\n",
    "df.churn = df.churn == \"yes\"\n",
    "df.churn = df.churn.astype(int)\n",
    "\n",
    "df.churn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "# Setting Up The Validation Framework\n",
    "\n",
    "perform the train/validation/test split with scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "len(df_full_train), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 = 1/4 = 0.25\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_test), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.churn.values\n",
    "y_val = df_val.churn.values\n",
    "y_test = df_test.churn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train[\"churn\"]\n",
    "del df_val[\"churn\"]\n",
    "del df_test[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# EDA (Exploratory data analysis)\n",
    "\n",
    "Checking missing values\n",
    "Looking at the distribution of the target variable (churn)\n",
    "Looking at numerical and categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full_train.churn.value_counts())\n",
    "# the % of churn data than unchurn\n",
    "df_full_train.churn.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_churn_rate = df_full_train.churn.mean()\n",
    "round(global_churn_rate, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the category var\n",
    "print(\"*df_full_train.dtypes:\\n\", df_full_train.dtypes)\n",
    "\n",
    "numerical = [\"tenure\", \"monthlycharges\", \"totalcharges\"]\n",
    "\n",
    "print(\"*df_full_train.columns:\\n\", df_full_train.columns)\n",
    "categorical = [\n",
    "    \"gender\",\n",
    "    \"seniorcitizen\",\n",
    "    \"partner\",\n",
    "    \"dependents\",\n",
    "    \"phoneservice\",\n",
    "    \"multiplelines\",\n",
    "    \"internetservice\",\n",
    "    \"onlinesecurity\",\n",
    "    \"onlinebackup\",\n",
    "    \"deviceprotection\",\n",
    "    \"techsupport\",\n",
    "    \"streamingtv\",\n",
    "    \"streamingmovies\",\n",
    "    \"contract\",\n",
    "    \"paperlessbilling\",\n",
    "    \"paymentmethod\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train[categorical].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Churn Rate\n",
    "\n",
    "(the difference and the risk ratio as two important tools for assessing feature importance)\n",
    "global - group\n",
    "negative result <0 : the group is more likely to churn\n",
    "positive result >0 : the group is less likely to churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which feature affect more the churn\n",
    "\n",
    "churn_female = df_full_train[df_full_train.gender == \"female\"].churn.mean()\n",
    "print(churn_female)\n",
    "churn_male = df_full_train[df_full_train.gender == \"male\"].churn.mean()\n",
    "print(churn_male)\n",
    "\n",
    "print(\"\")\n",
    "# no affect of this feature\n",
    "print(global_churn_rate - churn_female)\n",
    "print(global_churn_rate - churn_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full_train.partner.value_counts())\n",
    "print(\"\")\n",
    "\n",
    "churn_partner = df_full_train[df_full_train.partner == \"yes\"].churn.mean()\n",
    "print(churn_partner)\n",
    "churn_no_partner = df_full_train[df_full_train.partner == \"no\"].churn.mean()\n",
    "print(churn_no_partner)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(global_churn_rate - churn_partner)\n",
    "# the result is negative (most likely the churn)\n",
    "print(global_churn_rate - churn_no_partner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "# Risk Ratio\n",
    "\n",
    "(measure the important of features)\n",
    "the group has result >1 is more likely to churn\n",
    "the group has result <1 is less likely to churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(churn_partner / global_churn_rate)\n",
    "print(churn_no_partner / global_churn_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Let’s take the data and group it by gender, and for each variable within the gender group, let’s calculate the average churn rate within that group and calculate the difference and risk. We can perform this analysis for all the variables, not just the gender variable.\n",
    "\n",
    "The SQL query would look like:\n",
    "\n",
    "SELECT\n",
    "gender,\n",
    "AVG(churn),\n",
    "AVG(churn) - global_churn AS diff,\n",
    "AVG(churn) / global_churn AS risk\n",
    "FROM\n",
    "date\n",
    "GROUP BY\n",
    "gender;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "df.groupby('x').y.agg([mean()]) - returns a dataframe with mean of y series grouped by x series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for c in categorical:\n",
    "    df_group = df_full_train.groupby(c).churn.agg([\"mean\", \"count\"])\n",
    "    df_group[\"diff\"] = df_group[\"mean\"] - global_churn_rate\n",
    "    df_group[\"risk\"] = df_group[\"mean\"] / global_churn_rate\n",
    "    display(df_group)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Feature importance: Mutual information\n",
    "\n",
    "(how much do we learn about churn if we have the information from a particular feature. So, it is a measure of the importance of a categorical variable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "print(mutual_info_score(df_full_train.churn, df_full_train.contract))\n",
    "print(\"contract\", mutual_info_score(df_full_train.contract, df_full_train.churn))\n",
    "\n",
    "# we learn nothing about churn if we know the gender\n",
    "print(\"gender\", mutual_info_score(df_full_train.churn, df_full_train.gender))\n",
    "\n",
    "print(\"partner\", mutual_info_score(df_full_train.churn, df_full_train.partner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, df_full_train.churn)\n",
    "\n",
    "\n",
    "mi = df_full_train[categorical].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Feature importance: Correlation\n",
    "\n",
    "(Correlation coefficient: measures the degree of dependency between two variables. This value is negative if one variable grows while the other decreases, and it is positive if both variables increase. Depending on its size, the dependency between both variables could be low, moderate, or strong. It allows measuring the importance of numerical variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the correlation between x and y series. This is a function from pandas.\n",
    "df_full_train[numerical].corrwith(df_full_train.churn)\n",
    "# when increase the tenure lead to decrease the churn\n",
    "# when increase the monthlycharges lead to increase the churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 months\n",
    "print(df_full_train[df_full_train.tenure <= 2].churn.mean())\n",
    "\n",
    "print(df_full_train[df_full_train.tenure > 2].churn.mean())\n",
    "\n",
    "print(\n",
    "    df_full_train[\n",
    "        (df_full_train.tenure > 2) & (df_full_train.tenure <= 12)\n",
    "    ].churn.mean()\n",
    ")\n",
    "\n",
    "print(df_full_train[df_full_train.tenure > 12].churn.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what the mean of churn when values of feature is <cond>\n",
    "print(df_full_train[df_full_train.monthlycharges <= 20].churn.mean())\n",
    "\n",
    "print(\n",
    "    df_full_train[\n",
    "        (df_full_train.monthlycharges > 20) & (df_full_train.monthlycharges <= 50)\n",
    "    ].churn.mean()\n",
    ")\n",
    "\n",
    "print(df_full_train[df_full_train.monthlycharges > 50].churn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "(encode categorical features to binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feilds of one column depends on the nunique (not numeric) value have ,then fill it will 0,1\n",
    "# if the value of col is num ,will leave it like it is\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# ex.\n",
    "# print(df_train[[\"gender\", \"contract\"]].iloc[:50])\n",
    "# train_dicts = df_train[[\"gender\", \"contract\"]].iloc[:50].to_dict(orient=\"records\")\n",
    "# train_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train[categorical + numerical])\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient=\"records\")\n",
    "train_dicts\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# init dv and transform the features\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "print(dv.feature_names_)\n",
    "print(X_train.shape)\n",
    "print(X_train[0])\n",
    "\n",
    "# val transform\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "(same formula for linear reg but the result is from 0 to 1 , not from -infinty to +infinty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + numpy.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex.\n",
    "z = numpy.linspace(-7, 7, 51)\n",
    "print(z)\n",
    "sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(z, sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex\n",
    "# def logistic_regression(xi):\n",
    "#     score = w0\n",
    "\n",
    "#     for j in range(len(w)):\n",
    "#         score = score + xi[j] * w[j]\n",
    "\n",
    "#     result = sigmoid(score)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "# Training Logistic Regression with Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "# training the logistic regression model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the bias or intercept of the LR model\n",
    "model.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the coefficients or weights of the LR model\n",
    "model.coef_[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the x dataset by returning two columns with their probabilities for the two categories - soft predictions\n",
    "y_pred = model.predict_proba(X_val)[:, 1]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_decision = y_pred >= 0.5\n",
    "# to send the email for these customer ids\n",
    "df_val[churn_decision].customerid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating the model\n",
    "(y_val == churn_decision).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "# Model interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the bias or intercept of the LR model\n",
    "model.intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the coefficients or weights of the LR model\n",
    "model.coef_[0].round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
